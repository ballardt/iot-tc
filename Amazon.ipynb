{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "\n",
    "We can limit ourselves to just the \"Electronics\" SearchIndex, since any IoT device will have at least some generic category there. When we do this, the number of items returned is fairly small in some cases.\n",
    "\n",
    "> **NOTE:** Maximum number of items returned is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Amazon\", page 1\n",
      "Searching for \"Amazon\", page 2\n",
      "Searching for \"Amazon\", page 3\n",
      "Searching for \"Amazon\", page 4\n",
      "Searching for \"Amazon\", page 5\n",
      "Searching for \"Amazon\", page 6\n",
      "Searching for \"Amazon\", page 7\n",
      "Error (Amazon_Echo, page 7): HTTP Error 503: Service Unavailable\n",
      "Searching for \"HP\", page 1\n",
      "Searching for \"HP\", page 2\n",
      "Searching for \"HP\", page 3\n",
      "Searching for \"HP\", page 4\n",
      "Searching for \"HP\", page 5\n",
      "Searching for \"HP\", page 6\n",
      "Searching for \"HP\", page 7\n",
      "Searching for \"HP\", page 8\n",
      "Searching for \"HP\", page 9\n",
      "Searching for \"HP\", page 10\n",
      "Searching for \"HP\", page 11\n",
      "Searching for \"Dropcam\", page 1\n",
      "Searching for \"TP-LINK\", page 1\n",
      "Searching for \"TP-LINK\", page 2\n",
      "Searching for \"TP-LINK\", page 3\n",
      "Searching for \"TP-LINK\", page 4\n",
      "Searching for \"TP-LINK\", page 5\n",
      "Searching for \"TP-LINK\", page 6\n",
      "Searching for \"TP-LINK\", page 7\n",
      "Searching for \"TP-LINK\", page 8\n",
      "Searching for \"TP-LINK\", page 9\n",
      "Searching for \"TP-LINK\", page 10\n",
      "Searching for \"TP-LINK\", page 11\n",
      "Searching for \"pix-star\", page 1\n",
      "Searching for \"invoxia\", page 1\n",
      "Searching for \"invoxia\", page 2\n",
      "Searching for \"IPC\", page 1\n",
      "Searching for \"IPC\", page 2\n",
      "Searching for \"IPC\", page 3\n",
      "Searching for \"IPC\", page 4\n",
      "Searching for \"IPC\", page 5\n",
      "Searching for \"IPC\", page 6\n",
      "Searching for \"IPC\", page 7\n",
      "Searching for \"IPC\", page 8\n",
      "Error (Insteon_Camera, page 8): HTTP Error 503: Service Unavailable\n",
      "Searching for \"Netatmo\", page 1\n",
      "Searching for \"Netatmo\", page 2\n",
      "Searching for \"Physical\", page 1\n",
      "Searching for \"Physical\", page 2\n",
      "Searching for \"Physical\", page 3\n",
      "Searching for \"Physical\", page 4\n",
      "Searching for \"Physical\", page 5\n",
      "Searching for \"Physical\", page 6\n",
      "Searching for \"Physical\", page 7\n",
      "Searching for \"LIFX\", page 1\n",
      "Searching for \"Hanwha\", page 1\n",
      "Searching for \"Hanwha\", page 2\n",
      "Searching for \"Hanwha\", page 3\n",
      "Searching for \"Hanwha\", page 4\n",
      "Searching for \"Hanwha\", page 5\n",
      "Searching for \"Hanwha\", page 6\n",
      "Searching for \"Hanwha\", page 7\n",
      "Searching for \"Hanwha\", page 8\n",
      "Searching for \"Hanwha\", page 9\n",
      "Searching for \"Hanwha\", page 10\n",
      "Searching for \"Hanwha\", page 11\n",
      "Searching for \"SmartThings\", page 1\n",
      "Searching for \"SmartThings\", page 2\n",
      "\n",
      "Amazon_Echo..............|Amazon.........|60\n",
      "HP_Printer...............|HP.............|100\n",
      "Dropcam..................|Dropcam........|5\n",
      "TP-Link_Smart_Plug.......|TP-LINK........|100\n",
      "Pix-Star_Photo_Frame.....|pix-star.......|1\n",
      "Triby_Speaker............|invoxia........|10\n",
      "Insteon_Camera...........|IPC............|70\n",
      "Netatmo_Welcome..........|Netatmo........|10\n",
      "Smart_Things_O-field.....|Physical.......|61\n",
      "LiFX_Smart_Bulb..........|LIFX...........|1\n",
      "Samsung_Smartcam.........|Hanwha.........|100\n",
      "Smart_Things_ideal.......|SmartThings....|18\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import bottlenose\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "amazon = bottlenose.Amazon(\n",
    "    'AKIAJES52AQ7KXTBCE6A',\n",
    "    'rxgPzGinrfRZPFe50+tMo4eYknhkWfmhgEZJ2tyb',\n",
    "    'ballardt-20',\n",
    "    Parser=lambda text: BeautifulSoup(text, 'xml'))\n",
    "\n",
    "device_keywords = {\n",
    "    'Smart_Things_ideal': 'SmartThings',\n",
    "    'Smart_Things_O-field': 'Physical',\n",
    "    'Amazon_Echo': 'Amazon',\n",
    "    'Netatmo_Welcome': 'Netatmo',\n",
    "    'Samsung_Smartcam': 'Hanwha',\n",
    "    'Dropcam': 'Dropcam',\n",
    "    'Insteon_Camera': 'IPC',\n",
    "    #'Belkin_Wemo_Switch': 'xbcs',\n",
    "    'TP-Link_Smart_Plug': 'TP-LINK',\n",
    "    #'iHome': 'evrythng',\n",
    "    #'Belkin_Wemo_Motion_Sensor': 'xbcs',\n",
    "    'LiFX_Smart_Bulb': 'LIFX',\n",
    "    'Triby_Speaker': 'invoxia',\n",
    "    'Pix-Star_Photo_Frame': 'pix-star',\n",
    "    'HP_Printer': 'HP'\n",
    "}\n",
    "\n",
    "\n",
    "# Search for each device_keyword (only Electronics)\n",
    "search_results = {}\n",
    "for device,keyword in device_keywords.items():\n",
    "    search_results[device] = {}\n",
    "    has_more = True\n",
    "    page = 1\n",
    "    while has_more:\n",
    "        time.sleep(1.1)\n",
    "        try:\n",
    "            print('Searching for \"{}\", page {}'.format(keyword, page))\n",
    "            search_results[device][page] = amazon.ItemSearch(\n",
    "                #Keywords=keyword,\n",
    "                Brand=keyword,\n",
    "                SearchIndex='Electronics',\n",
    "                ResponseGroup='ItemAttributes, BrowseNodes',\n",
    "                ItemPage=page\n",
    "            )\n",
    "            if len(search_results[device][page].find_all('Item')) == 10:\n",
    "                page += 1\n",
    "            else:    \n",
    "                has_more = False\n",
    "        except HTTPError as err:\n",
    "            print('Error ({}, page {}): {}'.format(device, page, err))\n",
    "            has_more = False\n",
    "print()\n",
    "\n",
    "# Save to a file so we don't have to do this each time\n",
    "#with open('amazon_search_results.pickle', 'wb') as f:\n",
    "#    pickle.dump(search_results, f)\n",
    "\n",
    "# Show how many items exist for each device (keyword)\n",
    "result_counts = {}\n",
    "for device,pages in search_results.items():\n",
    "    result_counts[device] = 0\n",
    "    for page,result in pages.items():\n",
    "        result_counts[device] += len(result.find_all('Item'))\n",
    "    print('{0:.<25}|{1:.<15}|{2}'.format(device, device_keywords[device], result_counts[device]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we've already done this before, we can just load it.\n",
    "\n",
    "> **TODO:** Why is this giving a TypeError? Because of old PyQt4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-46d3ecd45886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amazon_search_results.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __new__() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('amazon_search_results.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2\n",
    "\n",
    "To better visualize the items returned, we can represent their hierarchical categories as a tree.\n",
    "\n",
    "> **NOTE:** Trees will be saved as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tree for Amazon_Echo...\n",
      "Done\n",
      "Constructing tree for HP_Printer...\n",
      "Done\n",
      "Constructing tree for Dropcam...\n",
      "Done\n",
      "Constructing tree for TP-Link_Smart_Plug...\n",
      "Done\n",
      "Constructing tree for Pix-Star_Photo_Frame...\n",
      "Done\n",
      "Constructing tree for Triby_Speaker...\n",
      "Done\n",
      "Constructing tree for Insteon_Camera...\n",
      "Done\n",
      "Constructing tree for Netatmo_Welcome...\n",
      "Done\n",
      "Constructing tree for Smart_Things_O-field...\n",
      "Done\n",
      "Constructing tree for LiFX_Smart_Bulb...\n",
      "Done\n",
      "Constructing tree for Samsung_Smartcam...\n",
      "Done\n",
      "Constructing tree for Smart_Things_ideal...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "from ete3 import Tree, TreeNode, TreeStyle, TextFace, NodeStyle, faces, CircleFace\n",
    "\n",
    "# Convert BrowseNodes XML into Python dicts for ease of use\n",
    "for device,pages in search_results.items():\n",
    "    print('Constructing tree for {}...'.format(device))\n",
    "    root = TreeNode()\n",
    "    root.name = 'root'\n",
    "    nodes = {}\n",
    "    all_pages = str(pages[1])#''.join(list(map(lambda x: str(x), pages.values())))\n",
    "    all_pages = '<AggResult>'+all_pages+'</AggResult>'\n",
    "    \n",
    "    # Get leaves (i.e. actual product category)\n",
    "    leaf_nodes = BeautifulSoup(all_pages, 'xml').select('BrowseNodes > BrowseNode')\n",
    "        \n",
    "    for leaf in leaf_nodes:\n",
    "        leaf_id = leaf.find('BrowseNodeId').string\n",
    "        if leaf_id not in nodes:\n",
    "            nodes[leaf_id] = {\n",
    "                'name': leaf.find('Name').string,\n",
    "                'leaf_count': 1,\n",
    "                'total_count': 1\n",
    "            }\n",
    "            leaf_treenode = TreeNode()\n",
    "            leaf_treenode.name = leaf_id\n",
    "            # Add text\n",
    "            category_name = TextFace(nodes[leaf_id]['name'])\n",
    "            category_name.margin_right = 5\n",
    "            category_name.margin_left = 30\n",
    "            category_name.margin_bottom = 5\n",
    "            category_name.margin_top = 10\n",
    "            leaf_treenode.add_face(category_name, column=0, position='branch-top')\n",
    "            nodes[leaf_id]['treenode'] = leaf_treenode\n",
    "        else:\n",
    "            nodes[leaf_id]['leaf_count'] += 1\n",
    "            nodes[leaf_id]['total_count'] += 1\n",
    "            leaf_treenode = nodes[leaf_id]['treenode']\n",
    "            \n",
    "        # Get ancestors\n",
    "        ancestor_node = leaf.find('Ancestors')\n",
    "        descendent_treenode = leaf_treenode\n",
    "        while ancestor_node is not None:\n",
    "            ancestor_id = ancestor_node.find('BrowseNodeId').string\n",
    "            ancestor_name = ancestor_node.find('Name')\n",
    "            if ancestor_name is not None:\n",
    "                ancestor_name = ancestor_name.string\n",
    "            else:\n",
    "                ancestor_name = 'NO_NAME'\n",
    "            if ancestor_id not in nodes:\n",
    "                nodes[ancestor_id] = {\n",
    "                    'name': ancestor_name,\n",
    "                    'leaf_count': 0,\n",
    "                    'total_count': 1\n",
    "                }\n",
    "                ancestor_treenode = TreeNode()\n",
    "                ancestor_treenode.name = ancestor_id\n",
    "                category_name = TextFace(nodes[ancestor_id]['name'])\n",
    "                category_name.margin_right = 5\n",
    "                category_name.margin_left = 30\n",
    "                category_name.margin_bottom = 5\n",
    "                category_name.margin_top = 10\n",
    "                ancestor_treenode.add_face(category_name, column=0, position='branch-top')\n",
    "                nodes[ancestor_id]['treenode'] = ancestor_treenode\n",
    "            else:\n",
    "                nodes[ancestor_id]['total_count'] += 1\n",
    "                ancestor_treenode = nodes[ancestor_id]['treenode']\n",
    "                \n",
    "            # Attach children to ancestors\n",
    "            child_names = [x.name for x in ancestor_treenode.children]\n",
    "            if descendent_treenode.name not in child_names:\n",
    "                ancestor_treenode.add_child(descendent_treenode)\n",
    "            descendent_treenode = ancestor_treenode\n",
    "            ancestor_node = ancestor_node.find('Ancestors')\n",
    "            \n",
    "        top_categories = [x.name for x in root.children]\n",
    "        if descendent_treenode.name not in top_categories:\n",
    "            root.add_child(descendent_treenode)\n",
    "            \n",
    "    ts = TreeStyle()\n",
    "    ts.show_leaf_name = False\n",
    "    ts.title.add_face(TextFace('{} (n=10)'.format(device), fsize=10), column=0)\n",
    "    for n_id, n_data in nodes.items():\n",
    "        leaf_count_text = TextFace('{} leaves'.format(n_data['leaf_count']))\n",
    "        leaf_count_text.margin_right = 5\n",
    "        leaf_count_text.margin_left = 30\n",
    "        leaf_count_text.margin_bottom = 5\n",
    "        leaf_count_text.margin_top = 5\n",
    "        total_count_text = TextFace('{} total'.format(n_data['total_count']))\n",
    "        total_count_text.margin_right = 5\n",
    "        total_count_text.margin_left = 30\n",
    "        total_count_text.margin_bottom = 5\n",
    "        total_count_text.margin_top = 5\n",
    "        n_data['treenode'].add_face(leaf_count_text, column=0, position='branch-bottom')\n",
    "        n_data['treenode'].add_face(total_count_text, column=0, position='branch-bottom')\n",
    "        n_style = NodeStyle()\n",
    "        n_data['treenode'].img_style['size'] = n_data['total_count'] + 3\n",
    "        if n_data['leaf_count'] > 0:\n",
    "            n_color = '#e83a3a'\n",
    "        else:\n",
    "            n_color = 'blue'\n",
    "        n_data['treenode'].img_style['fgcolor'] = n_color\n",
    "        \n",
    "    root.render(file_name='{}.png'.format(device), tree_style=ts)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Section 3\n",
    "\n",
    "While we don't extract the device search terms with code, we do follow an algorithm:\n",
    "\n",
    "    if (certificate has emailAddress):\n",
    "      use emailAddress domain name\n",
    "    \n",
    "    else if (certificate has O field):\n",
    "      use first word of O field\n",
    "      \n",
    "    else if (certificate has CN field):\n",
    "      use CN field domain name\n",
    "      \n",
    "    else:\n",
    "      this item cannot be used with Amazon\n",
    "      \n",
    "It works for the most part, but there are some instances where the first word of the O field gives misleading results. More generally, to detect when we've gotten bad keywords, one thing we can do is check how many brands get returned in the search results. If we search for a proper brand, we should mostly get its items. Conversely, if we search for a generic keyword, we might get a lot of different brands, which would be a hint that the keyword is bad.\n",
    "\n",
    "> **TODO:** If we can ever get around the 503 errors, see if different N values affect this. Also try to think of a way to consolidate different ways of saying the same company (e.g. HP & Hewlett Packard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 unique brands for Amazon_Echo\n",
      "2 unique brands for HP_Printer\n",
      "1 unique brands for Dropcam\n",
      "4 unique brands for TP-Link_Smart_Plug\n",
      "1 unique brands for Pix-Star_Photo_Frame\n",
      "1 unique brands for Triby_Speaker\n",
      "4 unique brands for Insteon_Camera\n",
      "1 unique brands for Netatmo_Welcome\n",
      "8 unique brands for Smart_Things_O-field\n",
      "1 unique brands for LiFX_Smart_Bulb\n",
      "4 unique brands for Samsung_Smartcam\n",
      "3 unique brands for Smart_Things_ideal\n"
     ]
    }
   ],
   "source": [
    "for device,pages in search_results.items():\n",
    "    all_pages = ''.join(list(map(lambda x: str(x), pages.values())))#str(pages[1])\n",
    "    all_pages = '<AggResult>'+all_pages+'</AggResult>'\n",
    "    manufacturers = BeautifulSoup(all_pages, 'xml').select('Manufacturer')\n",
    "    clean_mans = [''.join(c for c in m.string.split(' ',1)[0].lower() if c.isalnum()) for m in manufacturers]\n",
    "    num_unique_brands = len(set(clean_mans))\n",
    "    print('{} unique brands for {}'.format(num_unique_brands, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same vein, we expect a search by brand to yield items from the brand being searched for. Even if all of the items returned belong to a single brand, if that brand is different than the one we searched for, we may have used a generic keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon_Echo\n",
      "0.91 (60 right, 6 wrong, 66 total)\n",
      "\n",
      "HP_Printer\n",
      "1.00 (111 right, 0 wrong, 111 total)\n",
      "\n",
      "Dropcam\n",
      "0.80 (4 right, 1 wrong, 5 total)\n",
      "\n",
      "TP-Link_Smart_Plug\n",
      "0.99 (109 right, 1 wrong, 110 total)\n",
      "\n",
      "Pix-Star_Photo_Frame\n",
      "1.00 (2 right, 0 wrong, 2 total)\n",
      "\n",
      "Triby_Speaker\n",
      "1.00 (12 right, 0 wrong, 12 total)\n",
      "\n",
      "Insteon_Camera\n",
      "0.13 (10 right, 66 wrong, 76 total)\n",
      "\n",
      "Netatmo_Welcome\n",
      "1.00 (11 right, 0 wrong, 11 total)\n",
      "\n",
      "Smart_Things_O-field\n",
      "0.26 (18 right, 50 wrong, 68 total)\n",
      "\n",
      "LiFX_Smart_Bulb\n",
      "1.00 (2 right, 0 wrong, 2 total)\n",
      "\n",
      "Samsung_Smartcam\n",
      "0.52 (57 right, 53 wrong, 110 total)\n",
      "\n",
      "Smart_Things_ideal\n",
      "0.40 (8 right, 12 wrong, 20 total)\n"
     ]
    }
   ],
   "source": [
    "for device,pages in search_results.items():\n",
    "    all_pages = ''.join(list(map(lambda x: str(x), pages.values())))#str(pages[1])\n",
    "    all_pages = '<AggResult>'+all_pages+'</AggResult>'\n",
    "    manufacturers = BeautifulSoup(all_pages, 'xml').select('Brand')\n",
    "    clean_mans = [''.join(c for c in m.string.split(' ',1)[0].lower() if c.isalnum()) for m in manufacturers]\n",
    "    num_right = clean_mans.count(''.join(c for c in device_keywords[device].lower() if c.isalnum()))\n",
    "    num_wrong = len(clean_mans) - num_right\n",
    "    percent_right = num_right / len(clean_mans)\n",
    "    print()\n",
    "    print(device)\n",
    "    #print(device_keywords[device])\n",
    "    #print(clean_mans)\n",
    "    print('{:.2f} ({} right, {} wrong, {} total)'.format(percent_right, num_right, num_wrong, len(clean_mans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also be careful if the results from any of the 3 fields of interest (O, CN, and emailAddress) differ significantly from the rest\n",
    "\n",
    "> **TODO:** This may require more effort to test, both in coding it up and determing what metric to define success by. Should we look at how many literal items cross over? Or differences in brand name? What if different numbers of items are returned? Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device_keyword_fields = {\n",
    "    'SmartThings': {\n",
    "        'O': 'Physical',\n",
    "        'emailAddress': 'smartthings'\n",
    "    },\n",
    "    'Amazon_Echo': {\n",
    "        'O': 'Amazon',\n",
    "        'CN': 'amazon'\n",
    "    },\n",
    "    'Netatmo_Welcome': {\n",
    "        'O': 'Netatmo',\n",
    "        'CN': 'netatmo',\n",
    "        'emailAddress': 'netatmo'\n",
    "    },\n",
    "    'Samsung_SmartCam': {\n",
    "        'O': 'Hanwha Techwin',\n",
    "        'CN': 'samsungsmartcam'\n",
    "    },\n",
    "    'Dropcam': {\n",
    "        'O': 'Dropcam',\n",
    "        'CN': 'dropcam'\n",
    "    },\n",
    "    'Insteon_Camera': {\n",
    "        'O': 'IPCam',\n",
    "        'CN': 'IPC'\n",
    "    },\n",
    "    'TP-Link_Smart-Plug': {\n",
    "        'O': 'TP-LINK',\n",
    "        'CN': 'tplinkcloud'\n",
    "    },\n",
    "    'LiFX_Lightbulb': {\n",
    "        'O': 'LIFX',\n",
    "        'CN': 'lifx'\n",
    "    },\n",
    "    'Triby_Speaker': {\n",
    "        'O': 'invoxia',\n",
    "        'CN': 'invoxia',\n",
    "        'emailAddress': 'invoxia'\n",
    "    },\n",
    "    'Pix-Star_Photo-Frame': {\n",
    "        'CN': 'pix-star'\n",
    "    },\n",
    "    'HP_Printer': {\n",
    "        'O': 'HP',\n",
    "        'CN': 'hpeprint'\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
